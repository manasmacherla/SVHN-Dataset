{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import timeit\n",
    "import unittest\n",
    "\n",
    "## Please DONOT remove these lines. \n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "def compute_mean_std(svhn_dataset):\n",
    "    \"\"\"compute the mean and std of svhn dataset\n",
    "    Args:\n",
    "        svhn_training_dataset or cifar100_test_dataset\n",
    "        witch derived from class torch.utils.data\n",
    "    \n",
    "    Returns:\n",
    "        a tuple contains mean, std value of entire dataset\n",
    "    \"\"\"\n",
    "\n",
    "    data_r = numpy.dstack([svhn_dataset[i][0][0, :, :] for i in range(len(svhn_dataset))])\n",
    "    data_g = numpy.dstack([svhn_dataset[i][0][1, :, :] for i in range(len(svhn_dataset))])\n",
    "    data_b = numpy.dstack([svhn_dataset[i][0][2, :, :] for i in range(len(svhn_dataset))])\n",
    "    mean = numpy.mean(data_r), numpy.mean(data_g), numpy.mean(data_b)\n",
    "    std = numpy.std(data_r), numpy.std(data_g), numpy.std(data_b)\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "# mean, std = compute_mean_std(svhn_dataset)\n",
    "# print(mean)\n",
    "# print(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torchvision\n",
    "import scipy\n",
    "\"\"\"\n",
    "    Applying various transformations/preprocessing techniques on the dataset \n",
    "\"\"\"\n",
    "\n",
    "transform_svhn_train = transforms.Compose([\n",
    "        transforms.Resize(64, interpolation = 2), #increasing the image size using bilinear interpolation\n",
    "        #transforms.RandomResizedCrop(64),\n",
    "        #transforms.GaussianBlur(kernel_size = 3, sigma=(0.1, 2.0)),\n",
    "        #torchvision.transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False),\n",
    "        transforms.ToTensor(), # convert the image to a pytorch tensor\n",
    "        #transforms.RandomHorizontalFlip(), #random horizontal flipping with a probability of 0.5\n",
    "        #transforms.ColorJitter(brightness=0.4, saturation=0.4), # random color jittering with saturation and brightness\n",
    "        #transforms.Normalize((0.437, 0.443, 0.472), (0.198, 0.201, 0.197)),\n",
    "        transforms.Normalize((0.438, 0.444, 0.473), (0.195, 0.198, 0.195)),\n",
    "        \n",
    "        ])\n",
    "\n",
    "transform_svhn_test = transforms.Compose([\n",
    "        transforms.Resize(64, interpolation = 2), #increasing the image size using bilinear interpolation\n",
    "        transforms.ToTensor(), # convert the image to a pytorch tensor\n",
    "        transforms.Normalize((0.438, 0.444, 0.473), (0.195, 0.198, 0.195)),\n",
    "        \n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "train_dataset = torchvision.datasets.SVHN(root = \"./data_svhn\", split = \"train\", download = True, transform = transform_svhn_train)\n",
    "test_dataset = torchvision.datasets.SVHN(root = \"./data_svhn\", split = \"test\", download = True, transform = transform_svhn_test)\n",
    "\n",
    "# print(train_dataset[0][0])\n",
    "# image = train_dataset[0][0].permute(1,2,0)\n",
    "# image -= image.min() \n",
    "# image /= image.max()\n",
    "# print(image)\n",
    "# image = 255*image\n",
    "# plt.imshow(image)\n",
    "# print(image)\n",
    "# mean, std = compute_mean_std(train_dataset)\n",
    "# print(mean)\n",
    "# print(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Creating dataloaders for train and test datasets\n",
    "        Args:\n",
    "        batch_size = 32\n",
    "        shuffle = True for training set\n",
    "\"\"\"\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size = 32, shuffle = True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size = 32, shuffle = True)\n",
    "\n",
    "print(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the model\n",
    "\n",
    "def svhn_train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_id, (data, target) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        model.zero_grad() #calling the zero_grad function to flush out the gradients \n",
    "        output = model(data)\n",
    "        loss = nn.NLLLoss()(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_id%1000 == 0:\n",
    "            print('Train epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, batch_id*len(data), \n",
    "                        len(train_loader.dataset), 100. * batch_id/len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svhn_test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            target = torch.tensor(target, dtype = torch.long, device = device)\n",
    "            #print(target)\n",
    "            output = model(data)\n",
    "            test_loss += nn.NLLLoss()(output, target).item() #sum up batch loss\n",
    "            pred = output.argmax(dim =1, keepdim=True) #this is the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    return test_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVHNNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SVHNNet, self).__init__()\n",
    "        #### YOUR CODE STARTS HERE ####\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, stride=1)\n",
    "        self.norm1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, stride=1)\n",
    "        self.norm2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, stride=1)\n",
    "        self.norm3 = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(64, 128, 3, stride=1)\n",
    "        self.norm4 = nn.BatchNorm2d(128)\n",
    "        self.maxpool = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv5 = nn.Conv2d(128, 256, 3, stride=1)\n",
    "        self.norm5 = nn.BatchNorm2d(256)\n",
    "        self.conv6 = nn.Conv2d(256, 256, 3, stride=1)\n",
    "        self.norm6 = nn.BatchNorm2d(256)\n",
    "        self.conv7 = nn.Conv2d(256, 256, 3, stride=1)\n",
    "        self.norm7 = nn.BatchNorm2d(256)\n",
    "        self.conv8 = nn.Conv2d(256, 256, 3, stride=1)\n",
    "        self.norm8 = nn.BatchNorm2d(256)\n",
    "        self.dropout1 = nn.Dropout(p=0.25)\n",
    "        self.dropout2 = nn.Dropout(p=0.5)\n",
    "        self.fc1 = nn.Linear(in_features=256*10*10, out_features=1000)\n",
    "        self.fc2 = nn.Linear(1000,400)\n",
    "        self.fc3 = nn.Linear(400,100)\n",
    "        self.fc4 = nn.Linear(100,10)\n",
    "        self.act = nn.ReLU()\n",
    "        #### YOUR CODE ENDS HERE ####\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Use the layers defined above in a sequential way (folow the same as the layer definitions above) and \n",
    "        # write the forward pass, after each of conv1, conv2, conv3 and fc1 use a relu activation. \n",
    "        #### YOUR CODE STARTS HERE ####\n",
    "        x = self.conv1(x)\n",
    "        x = self.act(self.norm1(x))\n",
    "        x = self.conv2(x)\n",
    "        x = self.act(self.norm2(x))\n",
    "        x = self.conv3(x)\n",
    "        x = self.act(self.norm3(x))\n",
    "        x = self.conv4(x)\n",
    "        x = self.act(self.norm4(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.act(self.norm5(x))\n",
    "        x = self.conv6(x)\n",
    "        x = self.act(self.norm6(x))\n",
    "        x = self.conv7(x)\n",
    "        x = self.act(self.norm7(x))\n",
    "        x = self.conv8(x)\n",
    "        x = self.act(self.norm8(x))\n",
    "        x = self.maxpool(x)\n",
    "        #x = self.dropout1(x)\n",
    "        #x = self.dropout2(x)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        #print(x.size())\n",
    "        x = self.act(self.fc1(x))\n",
    "        x = self.act(self.fc2(x))\n",
    "        x = self.act(self.fc3(x))\n",
    "        x = self.act(self.fc4(x))\n",
    "        #### YOUR CODE ENDS HERE ####\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model = SVHNNet().to(device)\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "model.fc = nn.Linear(512, 10)\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Dropout(0.25),\n",
    "    nn.Linear(512, 10),\n",
    "    nn.LogSoftmax()\n",
    ")\n",
    "\n",
    "model.load_state_dict(torch.load(\"model_reg.pth\"))\n",
    "\n",
    "\n",
    "\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "    \n",
    "\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0000000001) #weight_decay = 0.0001\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.1, patience = 3, verbose=True)\n",
    "filepath = \"model_reg.pth\"\n",
    "\n",
    "start = timeit.default_timer()\n",
    "for epoch in range(1, 11):\n",
    "    svhn_train(model, device, train_dataloader, optimizer, epoch)\n",
    "    test_loss = svhn_test(model, device, test_dataloader)\n",
    "    scheduler.step(test_loss)\n",
    "\n",
    "torch.save(model.state_dict(), filepath)\n",
    "stop = timeit.default_timer()\n",
    "print('Total time taken: {} seconds'.format(int(stop - start)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DL4V_Assignment_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "carnd-gpu1",
   "language": "python",
   "name": "carnd-gpu1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
